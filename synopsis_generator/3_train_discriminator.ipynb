{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9685,
     "status": "ok",
     "timestamp": 1594657411515,
     "user": {
      "displayName": "Oliver De Jesus Rosario Reyes",
      "photoUrl": "",
      "userId": "08549433882715315538"
     },
     "user_tz": 240
    },
    "id": "ZKOzHmy0g4Ls",
    "outputId": "b1bfb9ca-9886-4aa0-9f98-6659cd488f0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x\n",
    "import os\n",
    "import tarfile\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "!pip install bert-tensorflow\n",
    "!pip install -q gpt-2-simple\n",
    "import gpt_2_simple as gpt2\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17096,
     "status": "ok",
     "timestamp": 1594657420067,
     "user": {
      "displayName": "Oliver De Jesus Rosario Reyes",
      "photoUrl": "",
      "userId": "08549433882715315538"
     },
     "user_tz": 240
    },
    "id": "hsZvic2YxnTz",
    "outputId": "d2b50623-3aec-4cf0-b1ce-98936d71c196"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "OUTPUT_DIR = 'tmp'\n",
    "\n",
    "gpt2.mount_gdrive()\n",
    "\n",
    "gpt2.copy_file_from_gdrive(\"bert_gan_real.csv\")\n",
    "\n",
    "real = pd.read_csv('bert_gan_real.csv')\n",
    "fakes = []\n",
    "for i in [\"400\", \"800\", \"1200\", \"1600\"]:\n",
    "  gpt2.copy_file_from_gdrive(f\"bert_gan_fake{i}.csv\")\n",
    "  fakes.append(pd.read_csv(f\"bert_gan_fake{i}.csv\"))\n",
    "fake = pd.concat(fakes)\n",
    "fake['synopsis']=fake['synopsis'].astype(str)\n",
    "fake['real']=0\n",
    "df = pd.concat([real,fake])[['tag','synopsis','real']].dropna()\n",
    "\n",
    "\n",
    "INPUT_COLUMN = 'tag'\n",
    "DATA_COLUMN = 'synopsis'\n",
    "LABEL_COLUMN = 'real'\n",
    "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
    "label_list = [0, 1]\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.1)\n",
    "\n",
    "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
    "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
    "                                                                   text_a = x[INPUT_COLUMN], \n",
    "                                                                   text_b = x[DATA_COLUMN], \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[INPUT_COLUMN], \n",
    "                                                                   text_b = x[DATA_COLUMN], \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "  return bert.tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()\n",
    "\n",
    "# We'll set sequences to be at most 128 tokens long.\n",
    "MAX_SEQ_LENGTH = 64\n",
    "# Convert our train and test features to InputFeatures that BERT understands.\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "  \"\"\"Creates a classification model.\"\"\"\n",
    "\n",
    "  bert_module = hub.Module(\n",
    "      BERT_MODEL_HUB,\n",
    "      trainable=True)\n",
    "  bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "  bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "\n",
    "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "  # Use \"sequence_outputs\" for token-level output.\n",
    "  output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "  hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "  # Create our own layer to tune for politeness data.\n",
    "  output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "  output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "  with tf.variable_scope(\"loss\"):\n",
    "\n",
    "    # Dropout helps prevent overfitting\n",
    "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "    logits = tf.nn.bias_add(logits, output_bias)\n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "    # Convert labels into one-hot encoding\n",
    "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "    if is_predicting:\n",
    "      return (predicted_labels, log_probs)\n",
    "\n",
    "    # If we're train/eval, compute loss between predicted and actual label\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "    return (loss, predicted_labels, log_probs)\n",
    "\n",
    "\n",
    "# model_fn_builder actually creates our model function\n",
    "# using the passed parameters for num_labels, learning_rate, etc.\n",
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
    "                     num_warmup_steps):\n",
    "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "    input_ids = features[\"input_ids\"]\n",
    "    input_mask = features[\"input_mask\"]\n",
    "    segment_ids = features[\"segment_ids\"]\n",
    "    label_ids = features[\"label_ids\"]\n",
    "\n",
    "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "    \n",
    "    # TRAIN and EVAL\n",
    "    if not is_predicting:\n",
    "\n",
    "      (loss, predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      train_op = bert.optimization.create_optimizer(\n",
    "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "      # Calculate evaluation metrics. \n",
    "      def metric_fn(label_ids, predicted_labels):\n",
    "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "        f1_score = tf.contrib.metrics.f1_score(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        auc = tf.metrics.auc(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        recall = tf.metrics.recall(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        precision = tf.metrics.precision(\n",
    "            label_ids,\n",
    "            predicted_labels) \n",
    "        true_pos = tf.metrics.true_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        true_neg = tf.metrics.true_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)   \n",
    "        false_pos = tf.metrics.false_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)  \n",
    "        false_neg = tf.metrics.false_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        return {\n",
    "            \"eval_accuracy\": accuracy,\n",
    "            \"f1_score\": f1_score,\n",
    "            \"auc\": auc,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"true_positives\": true_pos,\n",
    "            \"true_negatives\": true_neg,\n",
    "            \"false_positives\": false_pos,\n",
    "            \"false_negatives\": false_neg\n",
    "        }\n",
    "\n",
    "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "          loss=loss,\n",
    "          train_op=train_op)\n",
    "      else:\n",
    "          return tf.estimator.EstimatorSpec(mode=mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metrics)\n",
    "    else:\n",
    "      (predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      predictions = {\n",
    "          'probabilities': log_probs,\n",
    "          'labels': predicted_labels\n",
    "      }\n",
    "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "  # Return the actual model function in the closure\n",
    "  return model_fn\n",
    "\n",
    "# Compute train and warmup steps from batch size\n",
    "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 3.0\n",
    "# Warmup is a period of time where hte learning rate \n",
    "# is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 500\n",
    "SAVE_SUMMARY_STEPS = 100\n",
    "\n",
    "# Compute # train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "# Specify outpit directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
    "\n",
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})\n",
    "\n",
    "# Create an input function for training. drop_remainder = True for using TPUs.\n",
    "train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=False)\n",
    "\n",
    "test_input_fn = run_classifier.input_fn_builder(\n",
    "    features=test_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)\n",
    "\n",
    "def getPrediction(in_sentence_pairs):\n",
    "  labels = [\"Fake\", \"Real\"]\n",
    "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x[0], text_b = x[1], label = 0) for x in in_sentence_pairs] # here, \"\" is just a dummy label\n",
    "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
    "  predictions = estimator.predict(predict_input_fn)\n",
    "  return pd.DataFrame([(sentence[0], sentence[1], np.exp(prediction['probabilities'][1]), labels[prediction['labels']]) for sentence, prediction in zip(in_sentence_pairs, predictions)], columns=['tag', 'synopsis', 'prob_real','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1763,
     "status": "ok",
     "timestamp": 1594657421852,
     "user": {
      "displayName": "Oliver De Jesus Rosario Reyes",
      "photoUrl": "",
      "userId": "08549433882715315538"
     },
     "user_tz": 240
    },
    "id": "nucD4gluYJmK",
    "outputId": "31c8a73b-4cbb-4ab5-ca80-47b3ca86b983"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training!\n",
      "Training took time  0:00:00.006528\n"
     ]
    }
   ],
   "source": [
    "print(f'Beginning Training!')\n",
    "current_time = datetime.now()\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"Training took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24879,
     "status": "ok",
     "timestamp": 1594657444993,
     "user": {
      "displayName": "Oliver De Jesus Rosario Reyes",
      "photoUrl": "",
      "userId": "08549433882715315538"
     },
     "user_tz": 240
    },
    "id": "JIhejfpyJ8Bx",
    "outputId": "c9931f57-40f3-45e7-8aaf-985f2bf55e3c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc': 0.99701625,\n",
       " 'eval_accuracy': 0.9988889,\n",
       " 'f1_score': 0.99465233,\n",
       " 'false_negatives': 1.0,\n",
       " 'false_positives': 1.0,\n",
       " 'global_step': 1518,\n",
       " 'loss': 0.0053575495,\n",
       " 'precision': 0.9946524,\n",
       " 'recall': 0.9946524,\n",
       " 'true_negatives': 1612.0,\n",
       " 'true_positives': 186.0}"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.evaluate(input_fn=test_input_fn, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30569,
     "status": "ok",
     "timestamp": 1594657450700,
     "user": {
      "displayName": "Oliver De Jesus Rosario Reyes",
      "photoUrl": "",
      "userId": "08549433882715315538"
     },
     "user_tz": 240
    },
    "id": "pB9ebq7SSvea",
    "outputId": "b8feaba0-a31d-4e81-a727-67c7d8e95eef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>prob_real</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>rpg adventure indie</td>\n",
       "      <td>They came up with the name, story and gameplay...</td>\n",
       "      <td>0.040982</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>adventure</td>\n",
       "      <td>Using even more combinations of items througho...</td>\n",
       "      <td>0.979608</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>indie</td>\n",
       "      <td>In this game you are in a Chemistry lab, your ...</td>\n",
       "      <td>0.989638</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>adventure indie</td>\n",
       "      <td>The player will do whatever it takes to avoid...</td>\n",
       "      <td>0.991251</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>indie</td>\n",
       "      <td>How will you fare against the waves of failed ...</td>\n",
       "      <td>0.994333</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>adventure indie</td>\n",
       "      <td>government hire him -- a dealer of high-end an...</td>\n",
       "      <td>0.999906</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>adventure</td>\n",
       "      <td>Touted as the most romantic event to grace the...</td>\n",
       "      <td>0.999913</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>adventure</td>\n",
       "      <td>It's spring fair time and The Great Cow Race i...</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>strategy</td>\n",
       "      <td>Cinemaware's Anthology of classic games gives ...</td>\n",
       "      <td>0.999926</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>adventure indie</td>\n",
       "      <td>Is this all because of some sort of biological...</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tag  ... label\n",
       "180  rpg adventure indie  ...  Fake\n",
       "14             adventure  ...  Real\n",
       "77                 indie  ...  Real\n",
       "35       adventure indie  ...  Real\n",
       "169                indie  ...  Real\n",
       "..                   ...  ...   ...\n",
       "52       adventure indie  ...  Real\n",
       "95             adventure  ...  Real\n",
       "184            adventure  ...  Real\n",
       "15              strategy  ...  Real\n",
       "57       adventure indie  ...  Real\n",
       "\n",
       "[187 rows x 4 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_sent = test.loc[test['real']==1,['tag','synopsis']].values.tolist()\n",
    "predictions_real = getPrediction(real_sent)\n",
    "predictions_real.sort_values('prob_real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E3mwExbDyqQk"
   },
   "outputs": [],
   "source": [
    "x=[\"sci-fi[SEP] In the game you're playing as an agent of the company that manufactures the device called the T1. The task is to find out what is going on with the device\",\n",
    " \"sci-fi[SEP] In addition to the game's classic gameplay, the game also offers the ability to create custom levels for any size from a few hundred to a few thousand players. (We will be adding as we add additional content).Included in the game is the ability to create custom levels for any size from a few hundred to a few thousand players.\\n\\nThe game has many levels, including many levels inspired by classic games such as Age of Mythology, Zeos, etc.\\n\\nThe game has multiple difficulty settings, from simple to hardcore, which are sometimes customized for each user based upon their feedback.\\n\\nWe will be adding as we add additional content.\\n\\nThe game has many levels, including many levels inspired by classic games such as\",\n",
    " 'sci-fi[SEP]                                                                                                                                                      ',\n",
    " 'sci-fi[SEP]                                                                                                                                                      ',\n",
    " 'sci-fi[SEP] The game is a mix of classic games, with \"tons of new features\" which adds an extra challenge.The game has three difficulty settings: easy, normal, hardcore.                                                                                                                   ',\n",
    " \"sci-fi[SEP] \\n\\nA very different game set in a sci-fi setting, 'The Wing Commander' is a political simulator set in near future, where you can choose one or more of the 7 alien races and have to manage your military, crafting, logistics, and research capabilities. \\n\\nThe most powerful alien civilization is the 'Celestial Alliance', which is attacking Earth in order to conquer the solar system and have total control over all human technology.  \\n\\nExplore and manage your empire.\\n\\nIn THE WING COMMANDER you play as the commander of a human expedition in an alien spaceship, who is able to monitor and control every aspect of your world\",\n",
    " \"sci-fi[SEP]\\n\\nInto the heart of the city. You have been chosen by a secret society to hide out in a cave for the next 20 days. You must complete a series of challenges set by the Guardian to gain access to your cave and escape. The Guardian has to solve the puzzles, learn how to pick your way through the city and gather all the Pieces of the Guardian's Key that will allow you to pass the 20 days.\\n\\nThe game has no save feature\",\n",
    " 'sci-fi[SEP]                                                                                                                                                      ',\n",
    " 'sci-fi[SEP]                                                                                                                                                      ',\n",
    " 'sci-fi[SEP] Many hours of gameplay.Frequently Asked Questions:Q: \"What\\'s the difference between a shooting game and a VR game?\"A: \"Sniper VR\" is a shooter game.You do not need to buy a headset.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjmMe-79yvcS"
   },
   "outputs": [],
   "source": [
    "X = [re.sub('\\n', '', i) for i in x if i.strip() != \"sci-fi[SEP]\"]\n",
    "synopsis = [[s[:6], s[12:]] for s in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eQQykB7xzPWJ"
   },
   "outputs": [],
   "source": [
    "results = getPrediction(synopsis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6385,
     "status": "ok",
     "timestamp": 1594657457145,
     "user": {
      "displayName": "Oliver De Jesus Rosario Reyes",
      "photoUrl": "",
      "userId": "08549433882715315538"
     },
     "user_tz": 240
    },
    "id": "TKbeCvpgTmGg",
    "outputId": "1df45c2e-6c86-4236-a8ce-748cf183a0ba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>prob_real</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sci-fi</td>\n",
       "      <td>A very different game set in a sci-fi setting,...</td>\n",
       "      <td>0.998131</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sci-fi</td>\n",
       "      <td>nto the heart of the city. You have been chose...</td>\n",
       "      <td>0.045445</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sci-fi</td>\n",
       "      <td>Many hours of gameplay.Frequently Asked Questi...</td>\n",
       "      <td>0.016247</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sci-fi</td>\n",
       "      <td>In addition to the game's classic gameplay, th...</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sci-fi</td>\n",
       "      <td>In the game you're playing as an agent of the ...</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sci-fi</td>\n",
       "      <td>The game is a mix of classic games, with \"tons...</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tag                                           synopsis  prob_real label\n",
       "3  sci-fi  A very different game set in a sci-fi setting,...   0.998131  Real\n",
       "4  sci-fi  nto the heart of the city. You have been chose...   0.045445  Fake\n",
       "5  sci-fi  Many hours of gameplay.Frequently Asked Questi...   0.016247  Fake\n",
       "1  sci-fi  In addition to the game's classic gameplay, th...   0.000429  Fake\n",
       "0  sci-fi  In the game you're playing as an agent of the ...   0.000213  Fake\n",
       "2  sci-fi  The game is a mix of classic games, with \"tons...   0.000174  Fake"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by='prob_real', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Discriminator BERT.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/TheTuringExperience/gpt2-bert-reddit-bot/blob/master/colab_notebooks/training/2_train_realism_BERT.ipynb",
     "timestamp": 1592266938659
    },
    {
     "file_id": "https://github.com/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb",
     "timestamp": 1575507721809
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
